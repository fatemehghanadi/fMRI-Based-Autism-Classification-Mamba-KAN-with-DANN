{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfVU5wQ6OJmI"
      },
      "source": [
        "# installation Mamba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oceeCO7WXY6f"
      },
      "outputs": [],
      "source": [
        "# !conda create -n your_env_name python=3.10.13\n",
        "# !conda activate your_env_name\n",
        "!conda install cudatoolkit==11.8 -c nvidia\n",
        "!pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu118\n",
        "!conda install -c \"nvidia/label/cuda-11.8.0\" cuda-nvcc\n",
        "!conda install packaging\n",
        "# !pip install causal-conv1d==1.1.1\n",
        "# !pip install mamba-ssm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YARQJVyFQVdZ"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade scipy\n",
        "!pip install scipy==1.8.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5OAC4lO22iz"
      },
      "outputs": [],
      "source": [
        "!pip install mamba-ssm==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vT-ysEuRYwd"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade torcheeg\n",
        "!pip install torcheeg==1.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3ugEM0CZPtA"
      },
      "outputs": [],
      "source": [
        "# !pip install -U causal_conv1d\n",
        "!pip install causal-conv1d==1.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K-kq7EUiBc4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1LGdsnOEjhx"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "!pip install torcheeg\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "import os\n",
        "from torcheeg.trainers import DANNTrainer\n",
        "import math\n",
        "os.chdir('/content/drive/MyDrive/MyMethod')\n",
        "from efficient_kan.src.efficient_kan.kan import KAN\n",
        "\n",
        "!pip install nilearn\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "from nilearn.datasets import fetch_abide_pcp\n",
        "from nilearn.input_data import NiftiLabelsMasker\n",
        "from nilearn.datasets import fetch_atlas_craddock_2012\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from mamba_ssm import Mamba\n",
        "\n",
        "# import os\n",
        "# os.chdir('/content/mamba')\n",
        "# from mamba.mamba_ssm.modules.mamba_simple import Mamba\n",
        "\n",
        "batch, length, dim = 2, 64, 16\n",
        "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
        "model = Mamba(\n",
        "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
        "    d_model=dim, # Model dimension d_model\n",
        "    d_state=16,  # SSM state expansion factor\n",
        "    d_conv=4,    # Local convolution width\n",
        "    expand=2,    # Block expansion factor\n",
        ").to(\"cuda\")\n",
        "y = model(x)\n",
        "assert y.shape == x.shape\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xMQ6jl4bAi7"
      },
      "source": [
        "# DANN (Mamba-KAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvqjkMCwbXxD"
      },
      "source": [
        "## data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRHXeBBPexru"
      },
      "outputs": [],
      "source": [
        "!pip install nilearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8yHBEqwSHYb"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOO830GY5AND"
      },
      "outputs": [],
      "source": [
        "# Define PyTorch Dataset\n",
        "class fMRIDataset_domain(Dataset):\n",
        "    def __init__(self, fc, cc, labels, age, gender,numeric_institutions, fiq, viq, piq, eye,numeric_handedness ):\n",
        "        self.fc = torch.tensor(fc, dtype=torch.float32)\n",
        "        self.cc = torch.tensor(cc, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "        self.age = torch.tensor(age, dtype=torch.float32)\n",
        "        self.gender = torch.tensor(gender, dtype=torch.float32)\n",
        "        self.handedness = torch.tensor(numeric_handedness, dtype=torch.float32)\n",
        "        self.fiq = torch.tensor(fiq, dtype=torch.float32)\n",
        "        self.viq = torch.tensor(viq, dtype=torch.float32)\n",
        "        self.piq = torch.tensor(piq, dtype=torch.float32)\n",
        "        self.eye = torch.tensor(eye, dtype=torch.float32)\n",
        "        self.site = torch.tensor(numeric_institutions, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        fc_tensor = torch.tensor(self.fc, dtype=torch.float32).to(device)\n",
        "        cc_tensor = torch.tensor(self.cc, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "        # combined_tensors = CombinedTensors(fc_tensor[idx], cc_tensor[idx])\n",
        "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # combined_tensors = combined_tensors.to(device)\n",
        "\n",
        "\n",
        "\n",
        "        return [fc_tensor[idx], cc_tensor[idx]], self.labels[idx], self.site[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKDXdNpA_SDa"
      },
      "outputs": [],
      "source": [
        "def custom_collate_domain(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function to process a batch of (fc, cc, labels).\n",
        "\n",
        "    Args:\n",
        "        batch (list of tuples): Each tuple contains (fc, cc, labels).\n",
        "            - fc: torch.Tensor, shape (m, n)\n",
        "            - cc: torch.Tensor, shape (p)\n",
        "            - labels: torch.Tensor, shape (1) or (num_classes)\n",
        "\n",
        "    Returns:\n",
        "        concatenated_features (torch.Tensor): Batched features of shape (batch_size, m*n + p).\n",
        "        labels (torch.Tensor): Batched labels.\n",
        "    \"\"\"\n",
        "    # Flatten and concatenate fc and cc for each sample in the batch\n",
        "    features = [torch.cat((item[0][0].flatten(), item[0][1]), dim=0) for item in batch]\n",
        "    # Stack all features to form a batch\n",
        "    concatenated_features = torch.stack(features)\n",
        "    # Extract and stack labels\n",
        "    labels = torch.stack([item[1] for item in batch])\n",
        "    domains = torch.stack([item[2] for item in batch])\n",
        "\n",
        "\n",
        "    return concatenated_features, labels, domains\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR7Xgtngku5v"
      },
      "outputs": [],
      "source": [
        "# Define PyTorch Dataset\n",
        "class fMRIDataset(Dataset):\n",
        "    def __init__(self, fc, cc, labels, age, gender,numeric_institutions, fiq, viq, piq, eye,numeric_handedness ):\n",
        "        self.fc = torch.tensor(fc, dtype=torch.float32)\n",
        "        self.cc = torch.tensor(cc, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "        self.age = torch.tensor(age, dtype=torch.float32)\n",
        "        self.gender = torch.tensor(gender, dtype=torch.float32)\n",
        "        self.handedness = torch.tensor(numeric_handedness, dtype=torch.float32)\n",
        "        self.fiq = torch.tensor(fiq, dtype=torch.float32)\n",
        "        self.viq = torch.tensor(viq, dtype=torch.float32)\n",
        "        self.piq = torch.tensor(piq, dtype=torch.float32)\n",
        "        self.eye = torch.tensor(eye, dtype=torch.float32)\n",
        "        self.site = torch.tensor(numeric_institutions, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        fc_tensor = torch.tensor(self.fc, dtype=torch.float32).to(device)\n",
        "        cc_tensor = torch.tensor(self.cc, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "        # combined_tensors = CombinedTensors(fc_tensor[idx], cc_tensor[idx])\n",
        "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # combined_tensors = combined_tensors.to(device)\n",
        "\n",
        "\n",
        "\n",
        "        return [fc_tensor[idx], cc_tensor[idx]] , self.labels[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGjK3aRtk8_W"
      },
      "outputs": [],
      "source": [
        "# Define PyTorch Dataset\n",
        "class fMRIDataset_target(Dataset):\n",
        "    def __init__(self, fc, cc, labels, age, gender,numeric_institutions, fiq, viq, piq, eye,numeric_handedness ):\n",
        "        self.fc = torch.tensor(fc, dtype=torch.float32)\n",
        "        self.cc = torch.tensor(cc, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "        self.age = torch.tensor(age, dtype=torch.float32)\n",
        "        self.gender = torch.tensor(gender, dtype=torch.float32)\n",
        "        self.handedness = torch.tensor(numeric_handedness, dtype=torch.float32)\n",
        "        self.fiq = torch.tensor(fiq, dtype=torch.float32)\n",
        "        self.viq = torch.tensor(viq, dtype=torch.float32)\n",
        "        self.piq = torch.tensor(piq, dtype=torch.float32)\n",
        "        self.eye = torch.tensor(eye, dtype=torch.float32)\n",
        "        self.site = torch.tensor(numeric_institutions, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        fc_tensor = torch.tensor(self.fc, dtype=torch.float32).to(device)\n",
        "        cc_tensor = torch.tensor(self.cc, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "        # combined_tensors = CombinedTensors(fc_tensor[idx], cc_tensor[idx])\n",
        "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # combined_tensors = combined_tensors.to(device)\n",
        "\n",
        "\n",
        "\n",
        "        return [fc_tensor[idx], cc_tensor[idx]], self.site[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BptsEGealFxm"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function to process a batch of (fc, cc, labels).\n",
        "\n",
        "    Args:\n",
        "        batch (list of tuples): Each tuple contains (fc, cc, labels).\n",
        "            - fc: torch.Tensor, shape (m, n)\n",
        "            - cc: torch.Tensor, shape (p)\n",
        "            - labels: torch.Tensor, shape (1) or (num_classes)\n",
        "\n",
        "    Returns:\n",
        "        concatenated_features (torch.Tensor): Batched features of shape (batch_size, m*n + p).\n",
        "        labels (torch.Tensor): Batched labels.\n",
        "    \"\"\"\n",
        "    # Flatten and concatenate fc and cc for each sample in the batch\n",
        "    features = [torch.cat((item[0][0].flatten(), item[0][1]), dim=0) for item in batch]\n",
        "    # Stack all features to form a batch\n",
        "    concatenated_features = torch.stack(features)\n",
        "    # Extract and stack labels\n",
        "    labels = torch.stack([item[1] for item in batch])\n",
        "\n",
        "    return concatenated_features, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQmhuIrFmtCQ"
      },
      "outputs": [],
      "source": [
        "# > Determine if you want PCA or NOT below :\n",
        "PCA_flag = False\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "npz_file_path = '/content/drive/MyDrive/MyMethod/home/Dataset/ABIDE_CC400_NOTQC_TPE_withSITE_shuffle_randomSeed1234_filtGlobal.npz'\n",
        "# npz_file_path = '/content/drive/MyDrive/MyMethod/home/Dataset/ABIDE_CC200_PCC_withSITE_shuffle_randomSeed1234_.npz'\n",
        "\n",
        "\n",
        "cc_data = np.load(npz_file_path)\n",
        "\n",
        "# Extract data\n",
        "cc = cc_data[\"fc\"]  # Shape: (1035, 316, 392)\n",
        "print(cc.shape)\n",
        "cc_subject_ids = cc_data[\"subject\"]\n",
        "\n",
        "\n",
        "\n",
        "# Example arrays\n",
        "# A: Reference arrays (same shuffle)\n",
        "\n",
        "# Load data from .npz file\n",
        "npz_file_path = \"/content/drive/MyDrive/MyMethod/ABIDE_Data_Directory/ABIDE_CC400_NotCC_NotQC_shufflerandomSeed42.npz\"\n",
        "# npz_file_path = '/content/drive/MyDrive/MyMethod/home/Dataset/ABIDE_CC200_null_shuffle_randomSeed1234_.npz'\n",
        "\n",
        "data = np.load(npz_file_path)\n",
        "\n",
        "# B:\n",
        "# Extract keys\n",
        "fc = data[\"fc\"]  # Shape: (1035, 316, 392)\n",
        "print(fc.shape)\n",
        "labels = data[\"label\"]  # Shape: (1035,)\n",
        "subject_ids = data[\"subject\"]  # Shape: (1035,)\n",
        "age = data[\"age\"]  # Shape: (1035,)\n",
        "gender = data[\"gender\"]  # Shape: (1035,)\n",
        "handedness = data[\"handedness\"]  # Shape: (1035,)\n",
        "fiq = data[\"fiq\"]  # Shape: (1035,)\n",
        "viq = data[\"viq\"]  # Shape: (1035,)\n",
        "piq = data[\"piq\"]  # Shape: (1035,)\n",
        "eye = data[\"eye\"]\n",
        "site = data[\"site\"]\n",
        "# site = [item.split('_')[0] for item in data['subject']]\n",
        "\n",
        "# Adjust labels to start from 0\n",
        "labels -= labels.min()\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define the mapping\n",
        "handedness_mapping = {\n",
        "    'R': 0.0,           # Right -> 0.0\n",
        "    'L': 1.0,           # Left -> 1.0\n",
        "    'nan': 0.0 # nan -> 2.0\n",
        "}\n",
        "\n",
        "# Map values to float and handle 'nan' with a default value (e.g., -1.0)\n",
        "numeric_handedness = np.array([handedness_mapping.get(h, -1.0) for h in handedness], dtype=np.float32)\n",
        "\n",
        "# Check the result\n",
        "print(numeric_handedness)\n",
        "\n",
        "# Example array\n",
        "institutions =site\n",
        "# Step 1: Create a mapping for unique strings\n",
        "unique_values = np.unique(institutions)  # Find unique values\n",
        "string_to_num_mapping = {string: i for i, string in enumerate(unique_values)}\n",
        "\n",
        "# print(\"Mapping:\", string_to_num_mapping)\n",
        "\n",
        "# Step 2: Map the array using the dictionary\n",
        "numeric_institutions = np.array([string_to_num_mapping[string] for string in institutions], dtype=np.float32)\n",
        "\n",
        "# Step 3: Print the result\n",
        "# print(\"Original Array:\", institutions)\n",
        "# print(\"Numeric Array:\", numeric_institutions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Create a mapping from B_subject_ids to their indices in A_subject_ids\n",
        "A_to_index = {value: idx for idx, value in enumerate(cc_subject_ids)}\n",
        "\n",
        "# Step 2: Find indices in B_subject_ids that correspond to A_subject_ids\n",
        "matching_indices = [A_to_index[value] for value in subject_ids]\n",
        "\n",
        "# Step 3: Reorder all B arrays to match A\n",
        "subject_ids_aligned = subject_ids[np.argsort(matching_indices)]\n",
        "labels_aligned = labels[np.argsort(matching_indices)]\n",
        "data_aligned = fc[np.argsort(matching_indices)]\n",
        "age_aligned = age[np.argsort(matching_indices)]\n",
        "gender_aligned = gender[np.argsort(matching_indices)]\n",
        "handedness_aligned = numeric_handedness[np.argsort(matching_indices)]\n",
        "fiq_aligned = fiq[np.argsort(matching_indices)]\n",
        "viq_aligned = viq[np.argsort(matching_indices)]\n",
        "piq_aligned = piq[np.argsort(matching_indices)]\n",
        "eye_aligned = eye[np.argsort(matching_indices)]\n",
        "site_aligned = numeric_institutions[np.argsort(matching_indices)]\n",
        "\n",
        "\n",
        "# normalize\n",
        "def normalize_data(data):\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "    print((max_val - min_val))\n",
        "    normalized_data = (data - min_val) / (max_val - min_val)\n",
        "\n",
        "    return normalized_data\n",
        "age_aligned = normalize_data(age_aligned)\n",
        "\n",
        "fiq_aligned = [100 if x=='-9999' or x=='' or math.isnan(x) else x for x in fiq_aligned]\n",
        "fiq_aligned = normalize_data(fiq_aligned)\n",
        "viq_aligned = [100 if x=='-9999' or x=='' or math.isnan(x) else x for x in viq_aligned]\n",
        "viq_aligned = normalize_data(viq_aligned)\n",
        "piq_aligned = [100 if x=='-9999' or x=='' or math.isnan(x) else x for x in piq_aligned]\n",
        "piq_aligned = normalize_data(piq_aligned)\n",
        "# handedness_aligned = [1 if x=='R' or math.isnan(x) else 0 for x in handedness_aligned]\n",
        "handedness_aligned = normalize_data(handedness_aligned)\n",
        "eye_aligned = normalize_data(eye_aligned)\n",
        "\n",
        "\n",
        "\n",
        "# Get the upper triangle indices (excluding the diagonal)\n",
        "triu_indices = np.triu_indices(392, k=1)  # Exclude diagonal with k=1\n",
        "# Extract the upper triangular elements for each 2D slice\n",
        "upper_triangular = cc[:, triu_indices[0], triu_indices[1]]  # Shape: (1035, 76636)\n",
        "\n",
        "\n",
        "# filtered datloader -------------\n",
        "unique_sites, site_counts = np.unique(site_aligned, return_counts=True)\n",
        "most_common_site = unique_sites[np.argmax(site_counts)]\n",
        "print(f\"Site with most data: {most_common_site}, Count: {np.max(site_counts)}\")\n",
        "\n",
        "# Filter data for the selected site\n",
        "site_mask = site_aligned == most_common_site\n",
        "fc_filtered = data_aligned[site_mask]\n",
        "upper_triangular_filtered = upper_triangular[site_mask]\n",
        "site_filtered = site_aligned[site_mask]\n",
        "labels_filtered = labels_aligned[site_mask]\n",
        "age_filtered = age_aligned[site_mask]\n",
        "gender_filtered = gender_aligned[site_mask]\n",
        "handedness_filtered = handedness_aligned[site_mask]\n",
        "fiq_filtered = fiq_aligned[site_mask]\n",
        "viq_filtered = viq_aligned[site_mask]\n",
        "piq_filtered = piq_aligned[site_mask]\n",
        "eye_filtered = eye_aligned[site_mask]\n",
        "\n",
        "\n",
        "\n",
        "# Apply PCA\n",
        "if PCA_flag:\n",
        "  n_components_pca = 1028  # Number of principal components to keep\n",
        "  pca = PCA(n_components=n_components_pca)\n",
        "  upper_triangular_PCA = pca.fit(upper_triangular)\n",
        "  upper_triangular_PCA = pca.transform(upper_triangular)\n",
        "  upper_triangular_filtered_PCA = pca.transform(upper_triangular_filtered)\n",
        "  upper_triangular_filtered = upper_triangular_filtered_PCA\n",
        "  upper_triangular = upper_triangular_PCA\n",
        "  print(f'upper_triangular.shape:{upper_triangular.shape}')\n",
        "  print(f'upper_triangular_filtered.shape:{upper_triangular_filtered.shape}')\n",
        "\n",
        "\n",
        "\n",
        "# Create dataset and dataloader\n",
        "filtered_dataset = fMRIDataset_target(fc_filtered, upper_triangular_filtered, labels_filtered, age_filtered, gender_filtered,site_filtered, fiq_filtered, viq_filtered, piq_filtered, eye_filtered, handedness_filtered)\n",
        "filtered_loader = DataLoader(filtered_dataset, batch_size=8, shuffle=True, collate_fn=custom_collate)\n",
        "\n",
        "\n",
        "# ----------------------------------------------\n",
        "\n",
        "# Extract all existing data into a dictionary\n",
        "data_dict = {\n",
        "    'fc': data_aligned,\n",
        "    'cc': upper_triangular,\n",
        "    'age': age_aligned,\n",
        "    'gender': gender_aligned,\n",
        "    'handedness': handedness_aligned,\n",
        "    'fiq': fiq_aligned,\n",
        "    'viq': viq_aligned,\n",
        "    'piq': piq_aligned,\n",
        "    'labels': labels_aligned,\n",
        "    'subject_ids': subject_ids_aligned,\n",
        "    'eye': eye_aligned,\n",
        "    'site': site_aligned\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Verify alignment\n",
        "print(\"cc_subject_ids:\", cc_subject_ids)\n",
        "print(\"subject_ids_aligned:\", subject_ids_aligned)\n",
        "print(\"Is subject alignment correct?\", np.array_equal(cc_subject_ids, subject_ids_aligned))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckw9gZH_NrCj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Count the number of 0's\n",
        "count_zeros = np.count_nonzero(labels_aligned == 0)\n",
        "\n",
        "# Count the number of 1's\n",
        "count_ones = np.count_nonzero(labels_aligned == 1)\n",
        "\n",
        "print(f\"Number of 0's: {count_zeros}\")\n",
        "print(f\"Number of 1's: {count_ones}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXgCWaDFqyuD"
      },
      "outputs": [],
      "source": [
        "np.unique(site_aligned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gCzm7m0SYxj"
      },
      "outputs": [],
      "source": [
        "unique_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei2SSduSSfho"
      },
      "outputs": [],
      "source": [
        "string_to_num_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX6s7iP7IqmZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class KAN_Mamba_Class(nn.Module):\n",
        "    def __init__(self,  grid_size=12, spline_order=10, scale_noise=0.0, scale_base=1.0, scale_spline=1.0, grid_eps=0.02):\n",
        "        super(KAN_Mamba_Class, self).__init__()\n",
        "\n",
        "        self.device = 'cuda:0'\n",
        "        self.fc_layer1 = nn.Linear(76636, 512)\n",
        "\n",
        "        # Define the KAN layer with output size 2\n",
        "        self.kan_layer = KAN(\n",
        "                            # [dim_in, int(math.ceil(dim_in/2)), int(math.ceil(dim_in/8))],\n",
        "                             [512, 256],\n",
        "                             grid_size=grid_size, spline_order=spline_order, scale_noise=scale_noise,\n",
        "                             scale_base=scale_base, scale_spline=scale_spline, grid_eps=grid_eps).to('cuda:0')\n",
        "        self.relu_layer = nn.ReLU()\n",
        "        # Add a linear layer to map the ReLU output from size 4 to size 2\n",
        "        self.fc_layer2 = nn.Linear(256, 64)\n",
        "\n",
        "        # Define a softmax layer to output 2 classes\n",
        "        self.softmax_layer = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "        self.mamba = Mamba(\n",
        "            d_model=392,\n",
        "            d_state=128,\n",
        "            d_conv=4,\n",
        "            expand=2,\n",
        "            dt_min=0.001,\n",
        "            dt_max=0.1,\n",
        "            dt_init='random',\n",
        "            dt_scale=1.0,\n",
        "            dt_init_floor=1e-4,\n",
        "            conv_bias=True,\n",
        "            bias=False,\n",
        "            use_fast_path=True,\n",
        "            layer_idx=None\n",
        "        )\n",
        "        self.mamb_fc = nn.Sequential(\n",
        "            nn.Linear(392, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f'x.shape:{x.shape}')\n",
        "        num_data = x.shape[0]\n",
        "        m = x[:, 0:316*392] # fc\n",
        "        # print(f'm flat sahpe:{m.shape}')\n",
        "        m = m.reshape(num_data, 316, 392)\n",
        "        # m = torch.from_numpy(m)\n",
        "        m = m.to(self.device)\n",
        "\n",
        "        xx = x[:, 316*392:] # cc\n",
        "        # xx=torch.from_numpy(xx)\n",
        "        xx = xx.to(self.device)\n",
        "\n",
        "\n",
        "        # print(f'm.shape : {m.shape}')\n",
        "        # print(f'xx.shape : {xx.shape}')\n",
        "        # print(f\"fc_layer1.device: {next(self.fc_layer1.parameters()).device}\")\n",
        "\n",
        "        xx = self.fc_layer1(xx)\n",
        "        # Pass input through the KAN layer\n",
        "        kan_out = self.kan_layer(xx)\n",
        "        # Pass the output through the softmax layer for a 2-class output\n",
        "        xx=self.relu_layer(kan_out)\n",
        "        xx= self.fc_layer2(xx)\n",
        "        xx = self.softmax_layer(xx)\n",
        "\n",
        "        # print(f'--xx.shape:{xx.shape}')\n",
        "\n",
        "\n",
        "        # print(f'm input shape : {m.shape}')\n",
        "        m = self.mamba(m)\n",
        "        # print(f'm output shape : {m.shape}')\n",
        "        m = m.mean(dim=1)\n",
        "        # print(f'm AVG shape : {m.shape}')\n",
        "        m = self.mamb_fc(m)\n",
        "        m=self.softmax_layer(m)\n",
        "\n",
        "        # print(f'--m.shape:{m.shape}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return torch.cat((xx, m), dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acacqmfxzdMq"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_tsne_label(features, labels, epoch, n_components=2):\n",
        "    \"\"\"\n",
        "    Plot t-SNE visualization of features with points color-coded by their labels.\n",
        "    Supports 3 or more labels dynamically with custom label names.\n",
        "    \"\"\"\n",
        "    tsne = TSNE(n_components=n_components, random_state=42)\n",
        "    reduced_features = tsne.fit_transform(features)\n",
        "\n",
        "    # Map numerical labels to meaningful names\n",
        "    label_names = {0: \"ASD\", 1: \"TC\"}  # Add more mappings if needed\n",
        "\n",
        "    if n_components == 2:\n",
        "        # 2D Visualization\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.xlim(reduced_features[:, 0].min()-3 , reduced_features[:, 0].max()+3 )\n",
        "        plt.ylim(reduced_features[:, 1].min() -3, reduced_features[:, 1].max() +3)\n",
        "        unique_labels = np.unique(labels)\n",
        "        print(unique_labels)\n",
        "        colors = plt.cm.get_cmap('tab20', len(unique_labels))  # Dynamically generate colors\n",
        "\n",
        "        for idx, label in enumerate(unique_labels):\n",
        "            indices = np.where(labels == label)[0]\n",
        "            plt.scatter(\n",
        "                reduced_features[indices, 0],  # First t-SNE component\n",
        "                reduced_features[indices, 1],  # Second t-SNE component\n",
        "                label=label_names.get(label, f\"{label}\"),  # Use custom names or default\n",
        "                alpha=0.7,\n",
        "                color=colors(idx)\n",
        "            )\n",
        "\n",
        "        plt.title(f't-SNE Visualization of Features (Epoch {epoch})')\n",
        "        plt.xlabel('t-SNE Component 1')\n",
        "        plt.ylabel('t-SNE Component 2')\n",
        "        plt.legend(title=\"Labels\")\n",
        "        plt.grid(True)\n",
        "        # plt.savefig(f'./features_label_train_{epoch}.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_tsne_domain(features, labels, epoch, n_components=2):\n",
        "    \"\"\"\n",
        "    Plot t-SNE visualization of features with points color-coded by their labels.\n",
        "    Supports 3 or more labels dynamically with custom label names.\n",
        "    \"\"\"\n",
        "    tsne = TSNE(n_components=n_components, random_state=42)\n",
        "    reduced_features = tsne.fit_transform(features)\n",
        "\n",
        "    label_names = {\n",
        "    0: 'CALTECH',\n",
        "    1: 'CMU',\n",
        "    2: 'KKI',\n",
        "    3: 'LEUVEN_1',\n",
        "    4: 'LEUVEN_2',\n",
        "    5: 'MAX_MUN',\n",
        "    6: 'NYU',\n",
        "    7: 'OHSU',\n",
        "    8: 'OLIN',\n",
        "    9: 'PITT',\n",
        "    10: 'SBL',\n",
        "    11: 'SDSU',\n",
        "    12: 'STANFORD',\n",
        "    13: 'TRINITY',\n",
        "    14: 'UCLA_1',\n",
        "    15: 'UCLA_2',\n",
        "    16: 'UM_1',\n",
        "    17: 'UM_2',\n",
        "    18: 'USM',\n",
        "    19: 'YALE'\n",
        "      }\n",
        "\n",
        "\n",
        "    # Map numerical labels to meaningful names\n",
        "    # label_names = {0: \"ASD\", 1: \"TC\"}  # Add more mappings if needed\n",
        "\n",
        "    if n_components == 2:\n",
        "        # 2D Visualization\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.xlim(reduced_features[:, 0].min() -3 , reduced_features[:, 0].max() +3 )\n",
        "        plt.ylim(reduced_features[:, 1].min() -3, reduced_features[:, 1].max() +3)\n",
        "        unique_labels = np.unique(labels)\n",
        "\n",
        "        print(unique_labels)\n",
        "        colors = plt.cm.get_cmap('tab20', len(unique_labels))  # Dynamically generate colors\n",
        "\n",
        "        for idx, label in enumerate(unique_labels):\n",
        "            indices = np.where(labels == label)[0]\n",
        "            plt.scatter(\n",
        "                reduced_features[indices, 0],  # First t-SNE component\n",
        "                reduced_features[indices, 1],  # Second t-SNE component\n",
        "                label=label_names.get(label, f\"{label}\"),  # Use custom names or default\n",
        "                alpha=0.7,\n",
        "                color=colors(idx)\n",
        "            )\n",
        "\n",
        "        plt.title(f't-SNE Visualization of Features (Epoch {epoch})')\n",
        "        plt.xlabel('t-SNE Component 1')\n",
        "        plt.ylabel('t-SNE Component 2')\n",
        "        plt.legend(title=\"Labels\")\n",
        "        plt.grid(True)\n",
        "        # plt.savefig(f'./feature_domain_train_{epoch}.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ske8A-DXJFCq"
      },
      "outputs": [],
      "source": [
        "import torcheeg\n",
        "from torcheeg.trainers import DANNTrainer\n",
        "\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim=128, hidden_dim=64, output_dim=2, dropout_prob=0.5):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        device = 'cuda:0'\n",
        "        self.layers = nn.Sequential(KAN(\n",
        "                             [input_dim, hidden_dim],\n",
        "                             grid_size=5, spline_order=5, scale_noise=0.0, scale_base=1.0, scale_spline=1.0, grid_eps=0.02).to(device),\n",
        "            # nn.Linear(input_dim, hidden_dim),  # First linear layer\n",
        "            nn.ReLU(),                        # Activation function\n",
        "            nn.Dropout(dropout_prob),         # Dropout for regularization\n",
        "            nn.Linear(hidden_dim, output_dim), # Output layer for classification\n",
        "            nn.Softmax(dim=1)\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f'x shape in Classifier : {x.shape}')\n",
        "\n",
        "        return self.layers(x)\n",
        "\n",
        "class DomainClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=128, hidden_dim=64, output_dim=20, dropout_prob=0.5):\n",
        "        super(DomainClassifier, self).__init__()\n",
        "\n",
        "        device = 'cuda:0'\n",
        "        self.layers = nn.Sequential(\n",
        "            KAN([input_dim, hidden_dim],\n",
        "                             grid_size=5, spline_order=5, scale_noise=0.0, scale_base=1.0, scale_spline=1.0, grid_eps=0.02).to(device),  # First linear layer\n",
        "            nn.ReLU(),                        # Activation function\n",
        "            nn.Dropout(dropout_prob),         # Dropout for regularization\n",
        "            nn.Linear(hidden_dim, output_dim), # Output layer for domain classification\n",
        "            nn.Softmax(dim=1)\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f'x shape in Domain classifier : {x.shape}')\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "def kan_mamba_train_model(train_loader, val_loader,target_loader, val_loader_domain):\n",
        "\n",
        "    # extractor =  nn.Sequential(\n",
        "    #     nn.Linear(76636, 512),   # Reduce to intermediate dimensions\n",
        "    #     nn.ReLU(),\n",
        "    #     nn.Dropout(0.5),      # Dropout with a probability of 0.5\n",
        "    #     nn.Linear(512, 128),     # Final output layer (2 classes for classification)\n",
        "    # ).to(device)\n",
        "    device = 'cuda:0'\n",
        "    # extractor = KAN_Class(dim_in=76636, grid_size=12, spline_order=10, scale_noise=0.0, scale_base=1.0, scale_spline=1.0, grid_eps=0.02)\n",
        "    # extractor = KAN_Class(dim_in=76636, grid_size=12, spline_order=10, scale_noise=0.0, scale_base=1.0, scale_spline=1.0, grid_eps=0.02)\n",
        "    extractor = KAN_Mamba_Class().to(device)\n",
        "\n",
        "    # Initialize classifiers\n",
        "    classifier = Classifier(input_dim=128, hidden_dim=64, output_dim=2, dropout_prob=0.5).to(device)\n",
        "    domain_classifier = DomainClassifier(input_dim=128, hidden_dim=64, output_dim=20, dropout_prob=0.5).to(device)\n",
        "\n",
        "\n",
        "    # Define the classifier with dropout\n",
        "    # classifier = nn.Sequential(\n",
        "    #     nn.Linear(128, 64),   # Reduce to intermediate dimensions\n",
        "    #     nn.ReLU(),\n",
        "    #     nn.Dropout(0.5),      # Dropout with a probability of 0.5\n",
        "    #     nn.Linear(64, 2),     # Final output layer (2 classes for classification)\n",
        "    # ).to(device)\n",
        "\n",
        "    # # Define the domain classifier with dropout\n",
        "    # domain_classifier = nn.Sequential(\n",
        "    #     nn.Linear(128, 64),   # Reduce to intermediate dimensions\n",
        "    #     nn.ReLU(),\n",
        "    #     nn.Dropout(0.5),      # Dropout with a probability of 0.5\n",
        "    #     nn.Linear(64, 10),    # Final output layer (10 domains for domain classification)\n",
        "    # ).to(device)\n",
        "\n",
        "\n",
        "    trainer = DANNTrainer(extractor,\n",
        "                          classifier,\n",
        "                          domain_classifier,\n",
        "                          num_classes=2,\n",
        "                          devices=1,\n",
        "                          accelerator='gpu',\n",
        "                          lr_scheduler_decay = 0.75,\n",
        "                          lr=0.0001\n",
        "                          # lr=0.0000001\n",
        "                          )\n",
        "\n",
        "    source_loader = train_loader\n",
        "    # target_loader = target_loader\n",
        "\n",
        "    # trainer.fit(source_loader, target_loader, train_loader, max_epochs=5)  # !!! This was what V1 results.\n",
        "    for i in range(10):\n",
        "      print(f'//////////  {i}  \\\\\\\\\\\\\\\\\\\\\\\\')\n",
        "      trainer.fit(source_loader, target_loader, val_loader, max_epochs=1)\n",
        "      # R=trainer.test(val_loader) # !!! This was what V1 results.\n",
        "\n",
        "      # ---------------------------------\n",
        "      # ------------ TEST ---------------\n",
        "      # Assuming you have a trained `extractor` and `classifier`\n",
        "      all_preds = []\n",
        "      all_labels = []\n",
        "      all_domains = []\n",
        "      all_features = []\n",
        "\n",
        "      trainer.extractor.eval()\n",
        "      trainer.classifier.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for data, label, domain in val_loader_domain:\n",
        "\n",
        "              # print(f'domain is : {domain}')\n",
        "              # print(f'label is : {label}')\n",
        "\n",
        "              x = data.to(device)\n",
        "              # x = [tensor.to(device) for tensor in x]\n",
        "              # print(f'x.shape: {x.shape}')\n",
        "              y = label.to(device)\n",
        "              d = domain.to(device)\n",
        "              trainer.extractor = trainer.extractor.to(device)\n",
        "              trainer.classifier = trainer.classifier.to(device)\n",
        "              features = trainer.extractor(x)  # Extract features\n",
        "              all_features.append(features.cpu().numpy())\n",
        "              preds = trainer.classifier(features)  # Predict class probabilities\n",
        "              all_preds.append(preds.argmax(dim=1).cpu().numpy())  # Predicted labels\n",
        "              all_labels.append(y.cpu().numpy())  # True labels\n",
        "              all_domains.append(d.cpu().numpy())  # True labels\n",
        "\n",
        "\n",
        "      # Flatten lists into arrays\n",
        "      all_preds = np.concatenate(all_preds)\n",
        "      all_labels = np.concatenate(all_labels)\n",
        "      all_domains = np.concatenate(all_domains)\n",
        "      # all_domains = [item for sublist in all_domains for item in sublist]\n",
        "      # all_domains = np.array(all_domains)\n",
        "      print('**********************************************************')\n",
        "      print(all_labels)\n",
        "      print(all_domains)\n",
        "      all_features = np.concatenate(all_features)\n",
        "      # np.save(f'/content/drive/MyDrive/MyMethod/all_features_val_{i}.npy', all_features)\n",
        "\n",
        "\n",
        "      # Plot t-SNE label\n",
        "      plot_tsne_label(all_features, all_labels, epoch=i)\n",
        "\n",
        "      # Plot t-SNE domain\n",
        "      plot_tsne_domain(all_features, all_domains, epoch=i)\n",
        "\n",
        "\n",
        "      # Confusion Matrix\n",
        "      conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "      tn, fp, fn, tp = conf_matrix.ravel()  # For binary classification\n",
        "      accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "      specificity = tn / (tn + fp)\n",
        "\n",
        "\n",
        "      # Precision, Recall, F1 Score\n",
        "      precision = precision_score(all_labels, all_preds)\n",
        "      recall = recall_score(all_labels, all_preds)\n",
        "      f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "      # AUC (binary classification)\n",
        "      if len(np.unique(all_labels)) == 2:\n",
        "          auc = roc_auc_score(all_labels, all_preds)\n",
        "      else:\n",
        "          # For multiclass, use probabilities\n",
        "          all_preds_prob = classifier(features).softmax(dim=1).cpu().numpy()\n",
        "          auc = roc_auc_score(all_labels, all_preds_prob, multi_class='ovr')\n",
        "\n",
        "      # Print Results\n",
        "      print('------------------------------------')\n",
        "      print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "      print([tn, fp, fn, tp])\n",
        "      print(f\"Accuracy: {accuracy:.4f}\")\n",
        "      print(f\"Precision: {precision:.4f}\")\n",
        "      print(f\"Recall: {recall:.4f}\")\n",
        "      print(f\"Specificity: {specificity:.4f}\")\n",
        "      print(f\"F1 Score: {f1:.4f}\")\n",
        "      print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "      print(f'preds:{all_preds}')\n",
        "      print(f'all_labels:{all_labels}')\n",
        "      print('------------------------------------')\n",
        "\n",
        "      R = {'preds':all_preds, 'labels':all_labels, 'conf_mat':[tn, fp, fn, tp], 'acc':accuracy, 'pre':precision, 'rec':recall, 'spe':specificity, 'F1':f1, 'AUC':auc}\n",
        "    return R, all_features, trainer.classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2OGEbp0q-Bt"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKvnH0DEJE_m"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "cc = upper_triangular\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through folds\n",
        "fold = 1\n",
        "for i, (train_index, val_index) in enumerate(kf.split(cc)):\n",
        "  print(f\"Fold {fold}:\")\n",
        "  if i == 4:\n",
        "\n",
        "\n",
        "    # Split data\n",
        "    train_fc, val_fc = data_aligned[train_index], data_aligned[val_index]\n",
        "    train_cc, val_cc = cc[train_index], cc[val_index]\n",
        "    train_labels, val_labels = labels_aligned[train_index], labels_aligned[val_index]\n",
        "\n",
        "    train_age, val_age = age_aligned[train_index], age_aligned[val_index]\n",
        "    train_gender, val_gender = gender_aligned[train_index], gender_aligned[val_index]\n",
        "    train_handedness, val_handedness = handedness_aligned[train_index], handedness_aligned[val_index]\n",
        "    train_fiq, val_fiq = fiq_aligned[train_index], fiq_aligned[val_index]\n",
        "    train_viq, val_viq = viq_aligned[train_index], viq_aligned[val_index]\n",
        "    train_piq, val_piq = piq_aligned[train_index], piq_aligned[val_index]\n",
        "    train_eye, val_eye = eye_aligned[train_index], eye_aligned[val_index]\n",
        "    train_site, val_site = site_aligned[train_index], site_aligned[val_index]\n",
        "\n",
        "    print(f\"Train shape: {train_fc.shape}, Validation shape: {val_fc.shape}\")\n",
        "\n",
        "    # Create Dataset objects\n",
        "    train_dataset = fMRIDataset(train_fc,train_cc, train_labels, train_age, train_gender,train_site, train_fiq, train_viq, train_piq, train_eye, train_handedness)\n",
        "    val_dataset = fMRIDataset(    val_fc, val_cc, val_labels, val_age, val_gender,val_site, val_fiq, val_viq, val_piq, val_eye, val_handedness)\n",
        "    # test_dataset = fMRIDataset(test_fc, test_labels)\n",
        "    val_domain_dataset = fMRIDataset_domain(    val_fc, val_cc, val_labels, val_age, val_gender,val_site, val_fiq, val_viq, val_piq, val_eye, val_handedness)\n",
        "    train_domain_dataset = fMRIDataset_domain(train_fc,train_cc, train_labels, train_age, train_gender,train_site, train_fiq, train_viq, train_piq, train_eye, train_handedness)\n",
        "\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=custom_collate)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=custom_collate)\n",
        "\n",
        "    val_loader_domain = DataLoader(val_domain_dataset, batch_size=8, shuffle=False, collate_fn=custom_collate_domain)\n",
        "    train_loader_domain = DataLoader(train_domain_dataset, batch_size=8, shuffle=False, collate_fn=custom_collate_domain)\n",
        "\n",
        "\n",
        "\n",
        "    # Train your model here using train_fc and train_labels\n",
        "    # Validate on val_fc and val_labels\n",
        "    RR = kan_mamba_train_model(train_loader, val_loader, filtered_loader, train_loader_domain)\n",
        "\n",
        "  fold += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HOZRi7UrCcF"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsuZHD6ydsS0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "cc = upper_triangular\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through folds\n",
        "fold = 1\n",
        "for i, (train_index, val_index) in enumerate(kf.split(cc)):\n",
        "  print(f\"Fold {fold}:\")\n",
        "  if i == 4:\n",
        "\n",
        "\n",
        "    # Split data\n",
        "    train_fc, val_fc = data_aligned[train_index], data_aligned[val_index]\n",
        "    train_cc, val_cc = cc[train_index], cc[val_index]\n",
        "    train_labels, val_labels = labels_aligned[train_index], labels_aligned[val_index]\n",
        "\n",
        "    train_age, val_age = age_aligned[train_index], age_aligned[val_index]\n",
        "    train_gender, val_gender = gender_aligned[train_index], gender_aligned[val_index]\n",
        "    train_handedness, val_handedness = handedness_aligned[train_index], handedness_aligned[val_index]\n",
        "    train_fiq, val_fiq = fiq_aligned[train_index], fiq_aligned[val_index]\n",
        "    train_viq, val_viq = viq_aligned[train_index], viq_aligned[val_index]\n",
        "    train_piq, val_piq = piq_aligned[train_index], piq_aligned[val_index]\n",
        "    train_eye, val_eye = eye_aligned[train_index], eye_aligned[val_index]\n",
        "    train_site, val_site = site_aligned[train_index], site_aligned[val_index]\n",
        "\n",
        "    print(f\"Train shape: {train_fc.shape}, Validation shape: {val_fc.shape}\")\n",
        "\n",
        "    # Create Dataset objects\n",
        "    train_dataset = fMRIDataset(train_fc,train_cc, train_labels, train_age, train_gender,train_site, train_fiq, train_viq, train_piq, train_eye, train_handedness)\n",
        "    val_dataset = fMRIDataset(    val_fc, val_cc, val_labels, val_age, val_gender,val_site, val_fiq, val_viq, val_piq, val_eye, val_handedness)\n",
        "    # test_dataset = fMRIDataset(test_fc, test_labels)\n",
        "    val_domain_dataset = fMRIDataset_domain(    val_fc, val_cc, val_labels, val_age, val_gender,val_site, val_fiq, val_viq, val_piq, val_eye, val_handedness)\n",
        "    train_domain_dataset = fMRIDataset_domain(train_fc,train_cc, train_labels, train_age, train_gender,train_site, train_fiq, train_viq, train_piq, train_eye, train_handedness)\n",
        "\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=custom_collate)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=custom_collate)\n",
        "\n",
        "    val_loader_domain = DataLoader(val_domain_dataset, batch_size=8, shuffle=False, collate_fn=custom_collate_domain)\n",
        "    train_loader_domain = DataLoader(train_domain_dataset, batch_size=8, shuffle=False, collate_fn=custom_collate_domain)\n",
        "\n",
        "\n",
        "\n",
        "    # Train your model here using train_fc and train_labels\n",
        "    # Validate on val_fc and val_labels\n",
        "    RR = kan_mamba_train_model(train_loader, val_loader, filtered_loader, val_loader_domain)\n",
        "\n",
        "  fold += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wvqjkMCwbXxD",
        "_3rMvjlIOGAu",
        "FL7PhCvZlb9M",
        "s58Ru6L7lo8k",
        "iofwOQB0l-FU",
        "834VxOpQcCNN",
        "r13RDXgCcDKZ",
        "YF-5JJyA9DKD",
        "MZj_DhDpA7vP",
        "yH1bKmMG76PJ",
        "O-mHhHKhrXYg",
        "fxEA8GL1zzZl",
        "-sz4XGI9z3rZ",
        "jINp_RTaGyvx",
        "j8yHBEqwSHYb",
        "cOaIOT68gDIU",
        "B6ijzffp1Svt",
        "_cyTjuqH1wAa",
        "kVG0QyX7xdWE",
        "VMqeVQoqB7BT",
        "Ia3FM0ApvkRS",
        "fb9FDDUmgJMN",
        "rrk14riFyfDp",
        "fHeUBKyH3ixI",
        "nVp4M3nNsGmq",
        "1zv961Rmx4xF",
        "9W_1R-gJzorS",
        "0-FcO6QZl9dA",
        "L-lzv3MVerRY",
        "quHA2y2aAxFB",
        "t-vn53oNcIYu",
        "zrRMMJEXUBxa",
        "5A5FutrQ_93P",
        "t-2kjbtcF6f9",
        "e2OGEbp0q-Bt",
        "X6ZNxyZX13dI",
        "qOZ4W8QS18my",
        "YkBODoycjSzM",
        "rd8QR_TdpQot",
        "jf-fIEJQeHfX",
        "zoX-7G5YK0Cr",
        "w7sxOsd0u3qp",
        "tlb3C2D1A5IL"
      ],
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}